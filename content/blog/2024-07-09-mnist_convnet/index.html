---
title: "Deep Learning - A simple CNN to predict Handwritten Digits - MNIST dataset"
author: "Saulo Gil"
date: "2024-07-10"
excerpt: ''
subtitle: ''
draft: false
images: null
series: null
layout: single
slug: []
categories: []
tags: []
---



<!-- badges: start -->
<!-- badges: end -->
<div id="what-is-mnist-dataset" class="section level2">
<h2>ğŸ“’ What is MNIST datasetâ“</h2>
<p>Introduced by Yann LeCun and colleagues in the 1990s, the MNIST dataset has played a significant role in the development and evaluation of new algorithms in the field of machine learning and deep learning.</p>
<p>The MNIST dataset (Modified National Institute of Standards and Technology dataset) consists of a large database of handwritten digits. Here are some key points about the MNIST dataset:</p>
<ol style="list-style-type: decimal">
<li><strong>Content</strong>: It contains 60,000 training images and 10,000 testing images of handwritten digits (0-9). Each image is 28x28 pixels in grayscale.</li>
<li><strong>Format</strong>: The images are standardized, meaning each image is centered and size-normalized. Each pixel value ranges from 0 to 255, where 0 represents white and 255 represents black.</li>
<li><strong>Usage</strong>: The dataset is widely used for benchmarking machine learning algorithms, particularly in the field of image recognition and classification. Itâ€™s a common introductory dataset for learning and experimenting with neural networks and other machine learning models.</li>
<li><strong>Accessibility</strong>: The dataset is publicly available and can be easily accessed through various machine learning libraries, such as TensorFlow, PyTorch, and Keras.</li>
</ol>
</div>
<div id="what-is-convolutional-neural-network---cnn" class="section level2">
<h2>ğŸ“’ What is Convolutional Neural Network - CNNâ“</h2>
<p>A CNN is a type of deep learning algorithm specifically designed for processing structured grid data, such as images. CNNs are particularly effective for tasks such as image recognition, classification, and detection due to their ability to automatically and adaptively learn spatial hierarchies of features.</p>
<p>Here are some key components and concepts associated with CNNs:</p>
<ol style="list-style-type: decimal">
<li><strong>Convolutional Layers</strong>: These layers apply a convolution operation to the input, passing the result to the next layer. Convolutional layers consist of a set of learnable filters (or kernels) that are convolved with the input image to produce feature maps. Each filter detects different features, such as edges, textures, or more complex patterns.</li>
<li><strong>ReLU Activation Function</strong>: After each convolution operation, an activation function like the Rectified Linear Unit (ReLU) is applied. ReLU introduces non-linearity to the model, enabling it to learn more complex patterns.</li>
<li><strong>Pooling Layers</strong>: Also known as subsampling or downsampling, pooling layers reduce the dimensionality of each feature map while retaining the most important information. Max pooling, which takes the maximum value from a set of values in a feature map, is a common type of pooling.</li>
<li><strong>Fully Connected Layers</strong>: These layers are typically used towards the end of the network. Neurons in a fully connected layer have connections to all activations in the previous layer. They are responsible for combining the features extracted by the convolutional and pooling layers to make the final classification or prediction.</li>
<li><strong>Flattening</strong>: Before passing the data to fully connected layers, the output from the convolutional and pooling layers is often flattened into a one-dimensional vector.</li>
<li><strong>Dropout</strong>: This regularization technique involves randomly setting a fraction of input units to zero during training. Dropout helps prevent overfitting by ensuring that the model generalizes better to new data.</li>
<li><strong>Training</strong>: CNNs are trained using backpropagation and gradient descent. The objective is to minimize the loss function by adjusting the weights and biases of the network through iterative updates.</li>
</ol>
<p>CNNs have achieved state-of-the-art performance in many computer vision tasks, including object detection, facial recognition, and medical image analysis, among others.</p>
<p>Therefore, I utilized a CNN to predict handwritten digits from the MNIST dataset.</p>
<div id="lets-do-it" class="section level3">
<h3>Letâ€™s do itâ—</h3>
</div>
</div>
<div id="programming-language" class="section level2">
<h2>ğŸ‘¨â€ğŸ’» Programming language</h2>
<ul>
<li><img src="https://img.shields.io/badge/Python-gray?style=flat&amp;logo=python&amp;logoColor=white" /></li>
</ul>
</div>
<div id="libraries-necessaries" class="section level2">
<h2>ğŸ“¦ Libraries necessaries</h2>
<pre class="python"><code>import numpy as np
import keras
from keras import layers
import matplotlib.pyplot as plt
import tensorflow as tf</code></pre>
</div>
<div id="preparing-the-data" class="section level1">
<h1>ğŸ’» Preparing the data</h1>
<pre class="python"><code># Modelo / paramÃªtros dos dados
num_classes = 10
input_shape = (28, 28, 1)

# Downlaod dos dados e diviÃ§Ã£o em conjuntos de treinamento e teste
(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()

# Dimensione imagens para o intervalo [0, 1]
x_train = x_train.astype(&quot;float32&quot;) / 255
x_test = x_test.astype(&quot;float32&quot;) / 255

# Certifique-se de que as imagens tenham formato (28, 28, 1)
x_train = np.expand_dims(x_train, -1)
x_test = np.expand_dims(x_test, -1)
print(&quot;x_train shape:&quot;, x_train.shape)</code></pre>
<pre><code>## x_train shape: (60000, 28, 28, 1)</code></pre>
<pre class="python"><code>print(x_train.shape[0], &quot;train samples&quot;)</code></pre>
<pre><code>## 60000 train samples</code></pre>
<pre class="python"><code>print(x_test.shape[0], &quot;test samples&quot;)</code></pre>
<pre><code>## 10000 test samples</code></pre>
<pre class="python"><code>
# converter vetores de classe em matrizes de classe binÃ¡rias
y_train = keras.utils.to_categorical(y_train, num_classes)
y_test = keras.utils.to_categorical(y_test, num_classes)</code></pre>
<div id="looking-handwritten-digits-images" class="section level2">
<h2>ğŸ§ Looking handwritten digits images</h2>
<pre class="python"><code>plt.figure()
plt.imshow(x_train[0], cmap=plt.cm.binary)
plt.show()</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-3-1.png" width="672" /></p>
<p>Leâ€™ts see 10 imagens and its labels.</p>
<pre class="python"><code># Visualizar 10 imagens e seus rÃ³tulos
plt.figure(figsize=(15,10))
for i in range(25):
  plt.subplot(5,5,i+1)
  plt.xticks([])
  plt.yticks([])
  plt.imshow(x_train[i], cmap=plt.cm.binary)
  plt.xlabel(f&#39;Label: {np.argmax(y_train[i])}&#39;)
plt.show()</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-4-3.png" width="1440" /></p>
</div>
<div id="model---convolutional-neural-network---cnn" class="section level2">
<h2>ğŸ’»ğŸ§  Model - Convolutional Neural Network - CNN</h2>
<p>The CNN architecture used was developmented by FranÃ§ois Chollet.</p>
<p>This CNN achieved ~99% test accuracy.</p>
<p>The code is available in the <a href="https://colab.research.google.com/github/keras-team/keras-io/blob/master/examples/vision/ipynb/mnist_convnet.ipynb#scrollTo=xo9HwpE5gmQB">Google Colab</a>.</p>
<div id="who-is-franÃ§ois-chollet" class="section level3">
<h3>ğŸ¤” Who is FranÃ§ois Chollet?</h3>
<p>FranÃ§ois Chollet is a well-known figure in the field of artificial intelligence and deep learning.</p>
<p>He is the creator of Keras, one of the most popular libraries for deep learning (being used hereâ—), an interface for the TensorFlow library, among others, that simplifies the process of developing complex neural networks.</p>
<p>He has contributed to various research areas within machine learning and artificial intelligence, including computer vision, natural language processing, and the development of new machine learning architectures.</p>
<p>So, it is a good idea to use a CNN architecture development by him ğŸ˜œ.</p>
<div id="model-summary" class="section level4">
<h4>Model Summary</h4>
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ<span style="font-weight: bold"> Layer (type)                    </span>â”ƒ<span style="font-weight: bold"> Output Shape           </span>â”ƒ<span style="font-weight: bold">       Param # </span>â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ conv2d (<span style="color: #0087ff; text-decoration-color: #0087ff">Conv2D</span>)                 â”‚ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">26</span>, <span style="color: #00af00; text-decoration-color: #00af00">26</span>, <span style="color: #00af00; text-decoration-color: #00af00">32</span>)     â”‚           <span style="color: #00af00; text-decoration-color: #00af00">320</span> â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d (<span style="color: #0087ff; text-decoration-color: #0087ff">MaxPooling2D</span>)    â”‚ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">13</span>, <span style="color: #00af00; text-decoration-color: #00af00">13</span>, <span style="color: #00af00; text-decoration-color: #00af00">32</span>)     â”‚             <span style="color: #00af00; text-decoration-color: #00af00">0</span> â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_1 (<span style="color: #0087ff; text-decoration-color: #0087ff">Conv2D</span>)               â”‚ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">11</span>, <span style="color: #00af00; text-decoration-color: #00af00">11</span>, <span style="color: #00af00; text-decoration-color: #00af00">64</span>)     â”‚        <span style="color: #00af00; text-decoration-color: #00af00">18,496</span> â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d_1 (<span style="color: #0087ff; text-decoration-color: #0087ff">MaxPooling2D</span>)  â”‚ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">5</span>, <span style="color: #00af00; text-decoration-color: #00af00">5</span>, <span style="color: #00af00; text-decoration-color: #00af00">64</span>)       â”‚             <span style="color: #00af00; text-decoration-color: #00af00">0</span> â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ flatten (<span style="color: #0087ff; text-decoration-color: #0087ff">Flatten</span>)               â”‚ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">1600</span>)           â”‚             <span style="color: #00af00; text-decoration-color: #00af00">0</span> â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dropout (<span style="color: #0087ff; text-decoration-color: #0087ff">Dropout</span>)               â”‚ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">1600</span>)           â”‚             <span style="color: #00af00; text-decoration-color: #00af00">0</span> â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dense (<span style="color: #0087ff; text-decoration-color: #0087ff">Dense</span>)                   â”‚ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">10</span>)             â”‚        <span style="color: #00af00; text-decoration-color: #00af00">16,010</span> â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</pre>
<ul>
<li><p>Total params: 34,826 (136.04 KB)</p></li>
<li><p>Trainable params: 34,826 (136.04 KB)</p></li>
<li><p>Non-trainable params: 0 (0.00 B)</p></li>
</ul>
</div>
</div>
</div>
<div id="defining-a-callback-loss-function-optimizer-and-a-model-performance-metric." class="section level2">
<h2>ğŸ‘¨â€ğŸ’» Defining a callback, loss function, optimizer and, a model performance metric.</h2>
<pre class="python"><code>batch_size = 128
epochs = 15

# Callback para interromper o treinamento se a acurÃ¡cia atingir 90%
class myCallback(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get(&#39;accuracy&#39;)&gt;0.99):
      print(&quot;\nReached 90% accuracy so cancelling training!&quot;)
      self.model.stop_training = True

callbacks = myCallback()


# Adicionar paramÃªtros (loss function, otimizador e mÃ©trica de avaliaÃ§Ã£o)
model.compile(loss=&#39;categorical_crossentropy&#39;,
              optimizer=&#39;adam&#39;,
              metrics=[&#39;accuracy&#39;])</code></pre>
</div>
<div id="training-the-model" class="section level2">
<h2>ğŸ–¥ï¸ğŸª« Training the model</h2>
<p>Epoch 1/15
422/422 - 6s - 14ms/step - accuracy: 0.8906 - loss: 0.3653 - val_accuracy: 0.9763 - val_loss: 0.0905
Epoch 2/15
422/422 - 5s - 12ms/step - accuracy: 0.9649 - loss: 0.1135 - val_accuracy: 0.9848 - val_loss: 0.0635
Epoch 3/15
422/422 - 5s - 13ms/step - accuracy: 0.9749 - loss: 0.0832 - val_accuracy: 0.9868 - val_loss: 0.0493
Epoch 4/15
422/422 - 5s - 12ms/step - accuracy: 0.9786 - loss: 0.0695 - val_accuracy: 0.9883 - val_loss: 0.0430
Epoch 5/15
422/422 - 5s - 12ms/step - accuracy: 0.9808 - loss: 0.0619 - val_accuracy: 0.9877 - val_loss: 0.0431
Epoch 6/15
422/422 - 5s - 13ms/step - accuracy: 0.9825 - loss: 0.0548 - val_accuracy: 0.9902 - val_loss: 0.0368
Epoch 7/15
422/422 - 6s - 13ms/step - accuracy: 0.9840 - loss: 0.0509 - val_accuracy: 0.9908 - val_loss: 0.0339
Epoch 8/15
422/422 - 6s - 13ms/step - accuracy: 0.9853 - loss: 0.0464 - val_accuracy: 0.9917 - val_loss: 0.0319
Epoch 9/15
422/422 - 6s - 14ms/step - accuracy: 0.9858 - loss: 0.0444 - val_accuracy: 0.9913 - val_loss: 0.0324
Epoch 10/15
422/422 - 6s - 13ms/step - accuracy: 0.9870 - loss: 0.0410 - val_accuracy: 0.9918 - val_loss: 0.0295
Epoch 11/15
422/422 - 5s - 13ms/step - accuracy: 0.9876 - loss: 0.0392 - val_accuracy: 0.9917 - val_loss: 0.0324
Epoch 12/15
422/422 - 5s - 13ms/step - accuracy: 0.9881 - loss: 0.0377 - val_accuracy: 0.9918 - val_loss: 0.0321
Epoch 13/15
422/422 - 6s - 14ms/step - accuracy: 0.9892 - loss: 0.0334 - val_accuracy: 0.9915 - val_loss: 0.0310
Epoch 14/15
422/422 - 6s - 14ms/step - accuracy: 0.9888 - loss: 0.0349 - val_accuracy: 0.9915 - val_loss: 0.0296
Epoch 15/15
422/422 - 6s - 13ms/step - accuracy: 0.9894 - loss: 0.0334 - val_accuracy: 0.9925 - val_loss: 0.0280</p>
</div>
<div id="evaluate-the-trained-model" class="section level2">
<h2>ğŸ¯ Evaluate the trained model</h2>
<pre class="python"><code>score = model.evaluate(x_test, y_test, verbose=0)
print(&quot;Test loss:&quot;, round(score[0], 2))</code></pre>
<pre><code>## Test loss: 0.02</code></pre>
<pre class="python"><code>print(&quot;Test accuracy:&quot;, round(score[1], 2))</code></pre>
<pre><code>## Test accuracy: 0.99</code></pre>
</div>
<div id="looking-the-predictions" class="section level2">
<h2>ğŸ§ Looking the predictions</h2>
<pre class="python"><code>predictions = model.predict(x_test)</code></pre>
<pre><code>## 
## [1m  1/313[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m14s[0m 47ms/step
## [1m 32/313[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 2ms/step  
## [1m 66/313[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 2ms/step
## [1m101/313[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 2ms/step
## [1m137/313[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 1ms/step
## [1m172/313[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 1ms/step
## [1m208/313[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 1ms/step
## [1m244/313[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 1ms/step
## [1m278/313[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 1ms/step
## [1m313/313[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 2ms/step
## [1m313/313[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 2ms/step</code></pre>
<div id="example---index-2" class="section level3">
<h3>Example - index 2</h3>
<pre class="python"><code>np.array(predictions[2])</code></pre>
<pre><code>## array([1.4560229e-07, 9.9981290e-01, 1.7064168e-06, 3.7038593e-08,
##        9.2095484e-05, 2.2477290e-07, 1.4061417e-06, 7.6603275e-05,
##        1.4733056e-05, 1.4462152e-07], dtype=float32)</code></pre>
<pre class="python"><code>np.argmax(predictions[2])</code></pre>
<pre><code>## 1</code></pre>
<p>As we can see, the highest probability is at index 1 (i.e., 9.99), indicating the value 1.</p>
</div>
</div>
<div id="lets-see-the-image" class="section level2">
<h2>Letâ€™s see the imageâ—</h2>
<pre class="python"><code>plt.figure()
plt.imshow(x_test[2], cmap=plt.cm.binary)
plt.show()</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-12-5.png" width="672" /></p>
</div>
<div id="now-lets-see-25-examples-and-predicted-labels." class="section level2">
<h2>ğŸ§ Now, letâ€™s see 25 examples and predicted labels.</h2>
<pre class="python"><code>plt.figure(figsize=(15,10))
for i in range(25):
  plt.subplot(5,5,i+1)
  plt.xticks([])
  plt.yticks([])
  plt.imshow(x_test[i], cmap=plt.cm.binary)
  plt.xlabel(f&#39;Predicted label: {np.argmax(predictions[i])}&#39;)
plt.show()</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-13-7.png" width="1440" /></p>
</div>
<div id="conclusion" class="section level2">
<h2>ğŸ¤“ Conclusion</h2>
<p>Indeed, the CNN architecture was able to predict accurately handwritten digits.</p>
<p>This is a simple application of CNNs, but it is noteworthy that this technique has been used to address complex real-world problems.</p>
<p>Hope you enjoyed it!</p>
<p><img src="https://us.123rf.com/450wm/alesika/alesika2008/alesika200800157/153702004-see-you-soon-inscription-handwritten-lettering-illustration-black-vector-text-in-speech-bubble-simpl.jpg?ver=6" /></p>
</div>
<div id="reference" class="section level2">
<h2>Reference</h2>
<ol style="list-style-type: decimal">
<li><a href="http://yann.lecun.com/exdb/mnist/">The MNIST database of handwritten digits</a></li>
<li><a href="https://colab.research.google.com/github/keras-team/keras-io/blob/master/examples/vision/ipynb/mnist_convnet.ipynb#scrollTo=xo9HwpE5gmQB">Chollet, F. A simple convnet that achieves ~99% test accuracy on MNIST.</a></li>
<li><a href="https://github.com/saulosgil/mnist_convnet">Jupyter notebook with codes</a></li>
</ol>
</div>
</div>
